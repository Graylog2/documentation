.. _configure_multinode:

****************
Multi-node Setup
****************

This guide doesn't provide a step-by-step tutorial for building a multi-node Graylog cluster but does simply give some advice for questions that might arise during the setup.

It's important for such a project that you understand each step in the setup process and do some planning upfront. Without a proper roadmap of all the things you want to achieve with a Graylog cluster, you will be lost on the way.

Graylog should be the last component you install in this setup. Its dependencies, namely MongoDB and Elasticsearch, have to be up and running first.

.. important:: This guide doesn't include instructions for running a multi-node Graylog cluster in an untrusted network. We assume that the connection between the hosts is trusted and doesn't have to be secured individually.


Prerequisites
=============

Every server which is part of this setup should have the software requirements installed to run the targeted software. All software requirements can be found in the installation manual.

We highly recommend that the system time on all systems is kept in sync via NTP or a similar mechanism. Needless to say that DNS resolution must be working, too. Because everything is a freaking DNS problem.

In order to simplify the installation process, the servers should have a working Internet connection.

MongoDB replica set
===================

We recommend to `deploy a MongoDB replica set <https://docs.mongodb.com/manual/tutorial/deploy-replica-set/>`__.

MongoDB doesn't have to run on dedicated servers for the workload generated by Graylog, but you should follow the recommendations given in the MongoDB documentation about architecture. Most important is that you have an odd number of MongoDB servers in the replica set.

In most setups, each Graylog server will also host an instance of MongoDB which is part of the same replica set and shares the data with all other nodes in the cluster.

.. note:: To avoid unauthorized access to your MongoDB database, the `MongoDB replica set should be setup with authentication <https://docs.mongodb.com/v2.6/tutorial/deploy-replica-set-with-auth/>`__.

The correct order of working steps should be as follows:

1. Create the replica set (``rs01``)
2. Create the database (``graylog``)
3. Create a user account for accessing the database, which has the roles ``readWrite`` and ``dbAdmin``.

If your MongoDB needs to be reachable over network you should set the IP with ``bind_ip`` in the configuration.


Elasticsearch cluster
=====================

The `Elasticsearch setup documentation <https://www.elastic.co/guide/en/elasticsearch/reference/5.4/setup.html>`__ should help you to install Elasticsearch with a robust base configuration.

It is important to name the Elasticsearch cluster not simply named `elasticsearch` to avoid accidental conflicts with Elasticsearch nodes using the default configuration. Just choose anything else (we recommend `graylog`), because this is the default name and any Elasticsearch instance that is started in the same network will try to connect to this cluster.

The Elasticsearch servers need one IP that can be reached over network set in ``network.host`` and some participants of the cluster in ``discovery.zen.ping.unicast.hosts``. That is enough to have a minimal cluster setup.

When you secure your Elasticsearch with `User Authentication <https://www.elastic.co/guide/en/x-pack/5.4/xpack-security.html#preventing-unauthorized-access>`__ you need to add credentials to the `Graylog configuration <https://github.com/Graylog2/graylog2-server/blob/2.3.0-beta.1/misc/graylog.conf#L172-L178>`__ to be able to use the secured Elasticsearch cluster with Graylog.


Graylog Multi-node
==================

After the installation of Graylog, you should take care that only one Graylog node is configured to be master with the
configuration setting ``is_master = true``.

The HTTP settings configured in ``http_bind_address`` (or ``http_publish_uri``) must be accessable for all Graylog nodes
of the cluster.

This means, if ``http_bind_address`` is set to `0.0.0.0` you **must** set ``http_publish_uri``. ``http_publish_uri`` is
meant as an access point within the cluster for cluster intern communication. With ``http_bind_address = 0.0.0.0`` the
node cannot communicate its own IP to the other graylog nodes.


Graylog to MongoDB connection
-----------------------------

The ``mongodb_uri`` configuration setting must include all MongoDB nodes forming the replica set, the name of the replica set, as well as the previously configured user account with access to the replica set. The configuration setting is a normal `MongoDB connection string <https://docs.mongodb.com/manual/reference/connection-string/>`_.

Finally, the MongoDB connection string in the Graylog configuration file should look like this::

  mongodb_uri = mongodb://USERNAME:PASSWORD@mongodb-node01:27017,mongodb-node02:27017,mongodb-node03:27017/graylog?replicaSet=rs01


Graylog to Elasticsearch connection
-----------------------------------

Graylog will connect to the Elasticsearch `REST API <https://www.elastic.co/guide/en/elasticsearch/reference/5.4/_exploring_your_cluster.html>`__.

To avoid issues with the connection to the Elasticsearch cluster you should add some of the network addresses of the Elasticsearch nodes to ``elasticsearch_hosts``.


Graylog web interface
---------------------

It's possible to use a :ref:`loadbalancer <loadbalancer_integration>` in front of all Graylog servers, please refer to :ref:`configuring_webif_nginx` for more details.

Depending on your setup, it's possible to either use a hardware loadbalancer for TLS/HTTPS termination, a :ref:`reverse proxy <configuring_webif_nginx>`, or to simply enable it :ref:`in the Graylog node <ssl_setup>`.


Scaling
=======

Each component in this multi-node setup can be scaled on the individual needs.

Depending on the amount of messages ingested and how long messages should be available for direct search, the Elasticsearch cluster will need most of the resources on your setup.

Keep an eye on the Metrics of each part of the cluster. One option is to use `telegraf <https://github.com/influxdata/telegraf>`__ to fetch importand metrics and store them in your favorite metric system (e. g. Graphite, Prometheus or Influx).

Elasticseach Metrics and some administration can be done with `Elastic HQ <http://www.elastichq.org>`__ or `Cerebro <http://github.com/lmenezes/cerebro>`__. Those will help you to understand the Elasticsearch cluster health and behavior.

Graylog Metrics can be monitored `with the Graylog Metrics Reporter plugins <https://marketplace.graylog.org/addons/6fef88c7-94f7-488e-a6c5-bd6b71d8343e>`__ which are able to send the internal Graylog metrics to your favorite metrics collector (e. g. Graphite or Prometheus).

Up until today, we have almost never faced the issue that the MongoDB replica set needed special attention. But of course you should still monitor it and store its metrics - just to be sure.


Troubleshooting
===============

- After every configuration change or service restart, watch the logfile of the applications you have worked on. Sometimes other log files can also give you hints about what went wrong. For example if you're configuring Graylog and try to find out why the connection to the MongoDB isn't working, the MongoDB logs can help to identify the problem.
- If :ref:`HTTPS has been enabled for the Graylog REST API <ssl_setup>`, it need to be setup for the Graylog web interface, too.
